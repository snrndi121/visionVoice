1.Introduction
1.1 개발 배경
인간의 입의 시각적인 형태는 개인들에 대해 다양한 정보를 가지고 있다. 사람 외관에서 구별되는 부분일 수도 있고
사람의 감정을 표출하는 기능도 가지고 있다. 더욱이, 입술의 움직임은 어떤 사람이 말을 하고 있는지, 말을 하려고 하는지도
알려준다. 그러므로, 이미지나 비디오에서 정확한 입술의 경계를 구역화하는 것이 요구된다.(valueable information-)

 가장 명확한 예시는 @ASR (automatic speech recognition)인데, 미래의 인간 과학 인터페이스의 통합적인 부분으로
 고려되고 있다. 현재 최첨단 기술은 ASR를 기반으로한 오디오 시스템은 인간의 발음을 인지하고 노이지 환경에 있어서
 강건함 영역에서 여전히 부족함을 보이고 있다. @ASVR (audio-visual speech recognition)이라는 최근에 떠오르는 연구
 는 발화자의 입 모양과 발화 시그널을 연관짓는데 목표를 맞추고 있고, 물론 발화자의 비디오 이미지가 사용가능하다는 전제다.
 사람은 자신도 모르게 이 기술을 쓰고 있는데, 특히 @McGurk 효과에서 사용하고 있다. 예를 들어, '바'라는 발화가 '가'를
 말했는 거랑 중첩이되는 상황에서는 사람들은 '다'라고 인식한다. 일반적으로 오디오 정보없이 자동 음성 판독, 립 판독을 수행하는
 것은 불가능합니다. 이는 오디오와 같은 시각적 음성 기능의 모호성이 증가했기 때문입니다. / f / 및 / v / 사운드를 생성 할
 때의 입 위치는 실제로 동일합니다. 인간의 연설 말하기 언어에 대한 철저한 이해가 필요하지만 우선 무엇보다도 상황 적 상황과 발언의
 실용적 의미에 대해 알아야합니다. 연설하는 동안 입의 시각적 특징을 추출 할 수 있기 위해서는 입술 전체를 정확하게 찾아서 입 전체를
 찾는 것이 충분하지 않습니다 [4]. 입술은 매우 변형이 가능하며 사람마다 모양과 색상이 다양하여 특히 다양한 조명 상황에서 정확하고
 견고하게 위치를 찾고 추적하기가 어렵습니다.

 이를 달성하기위한 많은 접근법이 존재하는데, 이는 2 장에서 설명 될 것이다. 비록 이것이 시청각 음성 인식의 중심이 될 수 있지만,
 이 분야에서 가장 최근의 연구는 시각 기능 추출과 같은 ASVR 시스템의 고급 부분에 초점을두고있다. 결합 된 시청각 분류. 우리가
 아는 한, 현재 공개적으로 이용할 수있는 견고한 립 트래킹 솔루션이 없으며 시각적 특징 추출 및 후속 분류 단계에 대한 연구를 위한
 광범위한 테스트 데이터를 제공하는 데이터베이스도 없습니다. 분명히 고급 단계에 대한 조사는 입술이 뚜렷한 입의 클로즈업 비디오와
 같은 특수 데이터로 수행되었습니다.

 1.2 방법
 이 프로젝트에서는 여러 감지 방법을 기반으로 기능적인 입술 모양 추적기가 구현되었습니다. 프로그램의 핵심 부분은
 ASM (Active Shape Models)이라는 기법으로, 최종적이고 정확한 입술 윤곽 위치를 파악하는 데 사용됩니다.
 이 석사 논문은 ASM 현지화 방법을 구현하고 개선하는 데 중점을 둡니다. ASM은 Cootes and Taylor [5]에 의해
 처음 소개되었으며 다양한 형태의 현지화 작업에 적용될 수 있습니다. 이 기술은 강력하고 다재다능한 것으로 설명 되었기
 때문에 선택되었습니다.

ASM 파트 이전에는 이미지에 무엇이 있는지에 대한 자세한 정보를 얻으려면 여러 전처리 단계가 필요합니다.

얼굴 검출 단계에서, 이미지 프레임의 얼굴 영역이 검출되고 국소화된다. 이를 위해 선택된 알고리즘은 Viola와
Jones가 제안한 얼굴 탐지 방법을 사용하며 Viola-Jones 얼굴 탐지기라고도합니다 [7].

각각의 발견 된 얼굴 프레임에서, 두 눈 위치를 찾기 위해 눈 검출기가 실행된다. 이를 제공하는 알고리즘은 isophote 곡률을 사용하며 Valenti and Gevers [8]에 의해 설명되었습니다.

다음으로, 눈 위치를 입의 위치에 대한 지표로 사용하여 입만 포함하는 얼굴 프레임의 작은 부분을 찾습니다. 이 입 프레임을 관심 영역 (ROI)이라고합니다.

이를 위해 사용 된 방법은 Fanelli 등의 Hough Transform-based Mouth Localization이라는 논문에 설명되어있다. [9]. Gall and Lempintsky [10]에 기술 된 클래스 별 허프 포레스트의 특별한 적용입니다.

얼굴 프레임, 눈 위치 및 입 ROI가 주어지면 ASM을 사용하여보다 정확한 입술 위치를 지정합니다. 이 과정은 다음 장에서 자세히 설명 될 것입니다.

1.3 아키텍처 오버뷰
우리의 완벽한 립 현지화 프로그램을 LLASM이라고하며, 이는 '립 현지화 활성 형태 모델'을 의미합니다. 이미 나타낸 바와 같이, 하나의 단일 프레임을 처리하기위한 파이프 라인은 4 개의 주요 처리 부분으로 구성되어있다 (그림 1.1).

처음 세 부분은 이미지 처리에 유용한 도구를 제공하는 OpenCV 라이브러리를 사용하여 C ++에서 하나의 단일 응용 프로그램으로 구현됩니다.
특히 Haar-feature 분류기를 사용하는 Viola-Jones 얼굴 탐지기는 OpenCV에서 이미 구현되었습니다. 눈과 입의 ROI 검출기는 많은
OpenCV 기능을 사용하지만 코드는 다른 연구 프로젝트에서 나온 것으로 아직 실험 중입니다. 우리는이 외부 코드를 사용했고 크게 수정하지
않았습니다. 우리는 탐지기가 모두 의도 한대로 작동한다고 가정하지만, 특히 눈 탐지기는 때때로 잘못된 위치를 반환합니다.

이 석사 논문의 조사를 수행 한 ASM이있는 립 현지화 부분, 더 쉬운 데이터 처리 및 코드 단순성을 위해 Matlab에서 구현되었습니다.
이는 다른 개선 아이디어를 시도 할 때 도움이됩니다. 전체 처리 파이프 라인 알고리즘의 제어는 Matlab으로도 수행됩니다. 다시 말해,
단일 프레임의 경우 파이프 라인 스크립트는 C ++ 프로그램을 먼저 호출 한 후 ASM 립 로컬 라이저를 시작합니다. 이 제어 장치는 나중에
입술 추적 프로그램으로 확장됩니다.

1.4 보고서 목차
다음 장에서는 입술 국소화에 관한 관련 연구를 간략하게 검토 할 것입니다. 나머지 챕터는 ASM 립 현지화에 대한 조사를 다룰 것입니다. 그러므로 3 장에서는
얼굴 전체의 특징을 현지화하기 위해 설계된 ASM 방법을 원래 형태로 소개합니다.

이 석사 논문의 주요 기여는 다음과 같습니다. ASM 기반 알고리즘의 로컬라이제이션 품질을 향상시키기 위해 다양한 개선 방법이 조사되었습니다.
현지화 품질 측정 방법 및 해당 테스트에 사용 된 데이터베이스와 같은 적합성 테스트 조건은 4 장에 설명되어 있습니다. 5 장에서는 개별 알고리즘 개선 방법에 대해 자세히 설명합니다.

6 장에서는 단일 프레임 처리 파이프 라인을 입술 추적 프로그램으로 확장 한 방법과이를 수행 할 때 고려해야 할 사항에 대해 설명합니다. 5 장과 6 장에 설명 된 접근법의 수치 결과와 즉각적인 논의는 7 장에 나와 있습니다.

마지막 8 장은 이전 장의 결과를 요약하고 결론을 도출하며 추가 단계를 지적합니다.

#챕터2
#2.1 입술 지역화 기술
지난 15 년 동안 다양한 입술 위치 측정 방법이 문헌에 기술되어있다.

인기있는 접근 방식은 나머지 얼굴에서 입술을 분할하기 위해 색상 및 강도 임계 값을 기준으로합니다 [11, 12, 13, 14, 15].

일반적으로 입술은 주위에 모양 모델을 맞춰서 위치합니다.
많은 기술들이 연구 된 분절 된 입. 또 다른 널리 사용되는 방법은 구석 특징 탐지와 함께 뱀을 사용하는 것입니다 [16, 17].

또한 립 컨투어를 국소화하기 위해 모양 템플릿이 사용되었습니다 [18]. 다른 접근법은 입 영역에서 그림자의 다른 캐스팅을 특별히 고려하여 수평 및 수직 강도 프로파일에 따라 이미지의 영역을 분류하는 것입니다 [19].

실시간 입술 추적에 특히 중점을 둔 여러 출판물이 있습니다. 이들은 종종 위에서 언급 한 것과 동일한 방법을 사용하거나 단순화되거나 속도가 빠른 변형과 같은 방법을 사용합니다. 예를 들어
[20, 21, 22]는 위에서 설명한 것과 동일한 색 분할 기법을 사용합니다. 색상 분할 기반 접근 방식은 종종 조명 및 스피커의 변화, 특히 얼굴 털에 대한 견고성이 부족합니다. 이에 대한 흥미로운 해결책은 Petajan et al. [23], 콧 구멍의 개구부가 대략적인 입 위치를 결정하고 얼굴 털을 추정하는 데 사용되었습니다.

Yang 등은 더 간단한 접근법을 제안했는데, 특징 코너 특징을 가진 입술에서 6 개의 특징점 만 검색했다 [24].

#2.2. ASM(Active Shape Models)로 립 지역화
이 석사 논문은 입술을 찾는 문제에 능동형 모델을 적용하려는 첫 번째 시도가 아니며, 초기 조사는 Luettin et al. [25] 및 Matthews et al. [26]
들이다.

그러나 이전 간행물의 구현 및 테스트 세부 정보가 부족하고 프로그램 코드 나 테스트 데이터가 없기 때문에 이러한 결과를 재현 할 수 없었습니다.
추가 AVSR 처리 단계에 중점을 둡니다.

후자의 출판물에서, 연구 초점은 강력하고 다양한 립 국소화 ASM에 관한 것이 아니라 AVSR의 특징으로서 입술의 PCA-공간 표현의 적합성에 관한 것이다.
그 점에서, 모델은 나중에 입술을 감지하는 데 사용 된 것과 동일한 시퀀스에서 발췌하여 훈련되었습니다.

우리 프로젝트에서는 화자 독립적 모델이 목표입니다. 이러한 맥락에서 초기 로컬라이제이션 구현에 다목적 성, 정확성 및 견고성이 부족한 것은 놀라운 일이 아니므로이 주제에 대해 더 자세히 조사하기로 결정했습니다.

앞서 언급한 두 연구는 Cootes와 Talyor[5]의 원래 ASM 공식을 적용했는데 한 가지 주요한 변화가 있다.
공분산 매트릭스로 구성된 로컬 모양의 원래 프로파일 모델 대신, PCA 기반 그레이 레벨 분포 모델 (GLDM)을 도입한 점이다.

한편 Matthews et al. 또한 AAM (Active Appearance Model)이라는 ASM 확장의 사용에 대해서도 조사했습니다.
AAM의 매개 변수 벡터는보다 적합한 시각적 음성 기능을 제공하지만 조명 변화 및 다른 스피커와 관련하여 현지화가 얼마나
잘 작동했는지 강력하게 언급되어 있지는 않습니다.

보다 최근의 논문에서 Jang et al. GLDM을 대체하기위한 가우스 혼합 모델 (GMM) 사용을 제안한다 [27].
전반적인 탐지 품질은 약간만 향상되지만 안쪽 입술 윤곽의 배치는이 평균에 의해 크게 개선되었습니다.

#챕터3
#ASM (Active Shape Models)
ASM (Active Shape Model)이라는 용어는 이미지에서 특정 객체의 윤곽을 감지하는 데 사용되는 일련의 기술과 관련이 있습니다. 물체의 평균 모양을 이미지 위에 놓고
기본 개체의 윤곽에 맞게 변형하므로 이름이 '활성'입니다.

기본 기술은 1995 년 Cootes & Tayor에 의해 도입되었으며 그 이후로 많은 작업에 적용되고 적용되었습니다 [5].
좋은 참고 자료는 @Milborrow 의 ASM 을 이용한 얼굴 모양의 위치 찾기 [28]로, *ASM 알고리즘을 철저하게
설명하고 주제에 대한 실질적인 소개로 읽는 것이 좋습니다.*

이 장에서는이 프로젝트와 관련된 Cootes 및 Milborrow가 제안한 ASM 방법을 검토합니다. 두 보고서 모두 얼굴 특징을 찾는
방법을 설명하지만이 장에서는 이미 입술 모양에 개념을 적용합니다.

3.1 오버뷰
'ASM'과 관련하여 '모양'은 연결된 2 차원 점 (또는 점 구름)의 집합에 지나지 않습니다. 그러나, 그 연결점들은
모델의 변형 동작에 엄격한 영향을 미치지는 않습니다. 표준 ASM에서 저들의 수는 항상 동일하게 유지되며, 각 점은
오브젝트의 이미지에서 항상 같은 feature에 대응해야합니다. 점들의 'shape'는 객체의 특징점으로 간주될수있습니다.
예를 들어서, 입 모서리(@corner)는 입술 모양의 좋은 특징점입니다.

ASM을 사용하여 객체 경계를 찾는 것은 기계 학습 작업이며, 훈련 및 검색 알고리즘이 필요합니다. 교육 중에 작성되고
검색 중에 사용되는 모델은 다음 두 가지 주요 구성 요소고 구성됩니다.

1. Shape Model 또는 @PDM (Point distribution model)들은 훈련 중 관찰된 형태의 평균 형태와 분산을 설명하게 됩니다.
이것은 모든 샘플에서 서로에 대한 상대적인 점들의 위치들을 분석함으로써 이뤄집니다. 다시 말해, 이것은 훈련 중에 보이는 것과 같은
유요한 입 모양(shape)를 만들수 있는 모델입니다.

2. @Profile_model 은 객체 경계에 배치될때 각 모양 점의 일반적인 주변 모양을 설명하는 모델로(which describes each shape point’s typical neighborhood appearance when placed on the object boundary)(also called local structure model )

다음 섹션에서는 해당 구성 요소의 특성들을 설명하고 이 작업에서 어떻게 만들어지고 사용되어지는 지를 볼 수 있다.

#3.2 ASM 트레이닝
활성 형태 모델을 트레인하기 위해서는, 랜드마크가 찍혀있는 이미지들이 필요로한다. 이 연구에서 실제로 사용되는 트레이닝 셋트는
섹션4.1 에 기술되어 있다.

#3.2.1 The Shape Model
@Shape_Model은 트레이닝 세트에 제공된 'shape-point'좌표에 대해 주성분 분석(@PCA, principal component analysis)을 수행하여 만들어집니다.
PCA가 작동하려면 샘플 모양을 정렬해야 합니다. 이는 샘플 객체의 모양이 이미지에서 완전히 다른 위치에 있고 회전하고 크기가 다를 수 있기 때문입니다.

그 점들은 평균 Shape를 계산하고 Shape 변화를 분석을 수행하기 위해서, 반드시 공동 좌표로 변환되어야 합니다.
Cootes와 Milborrow가 사용하는 한 가지 방법은 @Procrustes분석 입니다. 이 분석의 결과는 주어진 모양을 참조 모양에
정렬하는 3x3 변환 행렬입니다 이 변환은 @최소제곱 접근법을 사용하여 해당하는 두 개의 shape의 점들 사이의 거리 합이
최소화되도록 합니다.이 방법에 대한 자세한 설명은 Cootes 보고서의 부록 C [29]에서 찾을 수 있으며, 여기에는 @affine_and_similarity
사례가 고려됩니다. 이것이 주어지면, 그림 3.1에 묘사 된 데이터 세트대로 먼저 모든 입술 모양, 즉 @point_cloud를 정렬 할 수 있습니다.
그 후 *PCA는 행렬이 아니라,데이터 벡터만 분석 할 수 있으므로 샘플 데이터를 벡터화해야합니다.*

이것은 다양한 방법으로 수행 할 수 있지만이 방법 선택이 출력에 큰 영향을 미치지 않습니다. 이 프로젝트에서이 작업을 수행 한 방법과 표기법을 소개합니다.
:데이터 세트는 56 개의 샘플 xk, k ∈ [1, .., 56]으로 구성되며, 각각은 20 포인트 p ~ k, i = (xk, i, yk, i), i ∈ [1, .., 20], xi 및 yi는 점의 픽셀 좌표입니다.각 샘플의 좌표 값은 2 : x ~ k = *(x k, 1, x k, 2, ..., x k, 20, y k, 1, ..., y k, 20) T로 하나의 벡터로 배열* 됩니다.

데이터가 벡터화되면 PCA를 최종적으로 수행 할 수 있습니다. 이것을 계산하는 방법은 여러 가지가 있으며 여기서는 사용한 방법을 설명합니다. 알고리즘 1은 계산 중에 수행 된 단계를 보여줍니다.

x̄는 평균 형태이고 S는 표본 치수의 공분산 행렬입니다. PCA 출력 x̄, Φ 및 λ는 다음 방정식에 사용됩니다.
*x̂ = x̄ + Φ · b*
여기서 x̂는 훈련 중에 본 샘플의 혼합 된 형태의 새로운 인스턴스입니다. 이 방정식은 평균 shape, x̄에 형상 특성 벡터 (Φ)를 추가하는 것으로 이해 될 수 있으며, 여기서 Φ의 각 벡터는 b = (b 1, b 2, ... b n) T의 요소에 의해 가중됩니다. 간단히 말해서, b를 지정하면 유효한 모양을 얻을 수 있습니다.

그러나, b는 자유롭게 선택 될 수 없으며, 그 원소는 방정식이 그럴듯한 모양을 생성하기 위해 특정 범위 내에 있어야합니다.
Φ에는 b의 값을 @fic3_2 로 제한하여 분산의 고유 벡터를 포함하기 때문입니다.

모델은 훈련 중에 보이는 모든 샘플을 재현 할 수 있습니다. 모델이 좀 더 극단적 인 모양을 허용하도록하려면이 제한을 늘릴 수 있습니다 (예 : 최대 3 λ i [29]. 이것은 훈련 중에 모든 분산이 보이지 않는 경우에 필요합니다. 이것이 일반적인 경우입니다.

  대응하는 고유 값 (λ i)의 크기에 따라 행렬 (Φ)에서 고유 벡터를 정렬함으로써, 가장 주성분이 발견 될 수있다.

  해당 고유 값이 클수록 고유 벡터에 의해 포함되는 변동량이 더 커집니다.

따라서 우리는 훈련 형태의 중요한 측면을 유지하지만 소음은 무시하기 때문에 고유 값이 큰 고유 벡터 만 고려하는 것이 좋습니다. 이것은 PCA 공간에서 특징 벡터의 표현 인 b의 차원 축소로 이어진다. 고유 벡터의 부분 집합에 포함되는 분산 량은 '@fic3_3'로 계산할 수 있습니다.

이 프로젝트에서, 보유 할 최적의 고유 벡터 수는 경험적 테스트에 의해 결정되었습니다. 대안 적으로,이 수는 총 분산 μ (k)의 특정 백분율에 의해 결정될 수 있습니다.


#3.2.2 Profile_model
프로파일 모델의 아이디어는 이미지에서 모양 특징점의 특징적인 이웃을 결정하는 것입니다. 검색 알고리즘은이 모델을 사용하여 가장 적합한 지점을 찾습니다.
주변, 즉 후보 지점의 주변이 모델의 주변과 얼마나 비슷한 지 비교하고 가장 유사한 것을 선택합니다.
